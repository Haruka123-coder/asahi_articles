name: Get Asahi Article Titles

#runs daily at 9 am BST
on:
    schedule;
    - cron: '0 8 * * *'  

permissions:
    contents: write

jobs:
    run-scraper:
        runs-on: ubuntu-latest
        steps:
            - name: Checkout repository
              uses: actions/checkout@v2

            - name: Set up Python
              uses: actions/setup-python@v2
              with:
                python-version: '3.8'

            - name: Install dependencies
              run: |
                python -m pip install --upgrade pip
                pip install requests beautifulsoup4

            - name: Run scraper script
              run: python scrape_asahi.py

            - name: Commit and push changes
              run: |
                git config --local user.name "GitHub Actions"
                git config --local user.email "actions@github.com"
                git add *.csv
                git commit -m  "update csv automatically by GitHub Actions"||echo "No changes to commit"
                git push